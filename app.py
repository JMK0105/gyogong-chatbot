import streamlit as st
import pandas as pd
import gspread
import json
from datetime import datetime
from google.oauth2 import service_account
from googleapiclient.discovery import build
import openai
import difflib
from fpdf import FPDF
import time
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt


# âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ êµìœ¡ê³µí•™ ê¸°ë°˜ì˜ í˜‘ë ¥í•™ìŠµì„ ì§€ì›í•˜ëŠ” ì§€ëŠ¥í˜• í”¼ë“œë°± ì±—ë´‡ì…ë‹ˆë‹¤.
ì´ íŒ€ì€ ì¤‘ë“± êµì‚¬ ëŒ€ìƒ ì›ê²© ì§ë¬´ì—°ìˆ˜ ì½˜í…ì¸ ì¸ ã€Œì—ë“€í…Œí¬ í™œìš© PBL ìˆ˜ì—… ì‹¤ì²œë²•ã€ì„ ì„¤ê³„í•˜ê³  ìˆìœ¼ë©°,
í•™ìƒë“¤ì€ ì‹¤ì œ êµìœ¡ í˜„ì¥ì—ì„œ ì ìš© ê°€ëŠ¥í•œ ìˆ˜ì—… ì‚¬ë¡€ê°€ í¬í•¨ëœ ê°•ì˜ ì½˜í…ì¸ ë¥¼ ê°œë°œí•´ì•¼ í•©ë‹ˆë‹¤.

ë³¸ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ í‰ê°€ ê¸°ì¤€ì— ê¸°ë°˜í•˜ì—¬ ìˆ˜í–‰ë©ë‹ˆë‹¤. íšŒì˜ ë‚´ìš©ì„ ë¶„ì„í•  ë•Œ ì´ ê¸°ì¤€ê³¼ ë¶€í•©í•˜ëŠ”ì§€ íŒë‹¨í•˜ê³ , ê·¸ì— ë”°ë¥¸ ë¶„ì„ê³¼ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”:

[ê³¼ì œ í‰ê°€ ê¸°ì¤€]
1. ê³¼ì • ì í•©ì„±: ì½˜í…ì¸  íë¦„ê³¼ ì»¨ì…‰ì´ â€˜ì¤‘ë“±êµì‚¬ ëŒ€ìƒ PBL ìˆ˜ì—… ì‹¤ì²œ ì—°ìˆ˜â€™ì— ì ì ˆí•œê°€?
2. ì‚¬ë¡€ì˜ êµ¬ì²´ì„±ê³¼ ì •í™•ì„±: ì œì‹œëœ ìˆ˜ì—… ì‚¬ë¡€ê°€ êµê³¼ ë° í•™ìŠµì ë§¥ë½ì— ë§ê³ , êµìœ¡ì  íƒ€ë‹¹ì„±ì„ ê°–ì¶”ì—ˆëŠ”ê°€?
3. ì ìš© ê°€ëŠ¥ì„±: êµì‚¬ê°€ ì‹¤ì œ ì ìš© ê°€ëŠ¥í•œ êµ¬ì²´ì„±ê³¼ í˜„ì‹¤ì„±ì„ ê°–ì¶”ì—ˆëŠ”ê°€?
4. ì½˜í…ì¸  êµ¬ì¡° ë° íë¦„: ê°•ì˜ì˜ ì „ì²´ êµ¬ì„±ê³¼ íë¦„ì´ ë…¼ë¦¬ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´ê°€?
5. ë‚´ìš© ì „ë‹¬ë ¥: êµì‚¬ê°€ ë“£ê³  ì‰½ê²Œ ì´í•´í•˜ê³  ë”°ë¼í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì—ˆëŠ”ê°€?

ì•„ë˜ëŠ” ì´ íŒ€ì˜ ëˆ„ì  íšŒì˜ ë‚´ìš© ìš”ì•½ê³¼ ì´ë²ˆ íšŒì˜ ë‚´ìš©ì…ë‹ˆë‹¤.
ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ 7ê°€ì§€ ì˜ì—­ì— ë”°ë¼ íšŒì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì„¸ìš”. ê° í•­ëª© ì´ë¦„ì„ ê·¸ëŒ€ë¡œ ì†Œì œëª©ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ êµ¬ë¶„í•˜ì„¸ìš”.
ë§ˆì§€ë§‰ì— 'ì˜í•œ ì ', 'ê°œì„ í•  ì ', 'ë‹¤ìŒ íšŒì˜ ì œì•ˆ'ì„ ìš”ì•½ í¬ì¸íŠ¸ë¡œ ì œê³µí•˜ì„¸ìš”.

7ê°€ì§€ ë¶„ì„ ì˜ì—­:
1. ì—­í•  ì •ë¦¬: ëˆ„ê°€ ì–´ë–¤ ì—­í• ì„ ë§¡ì•˜ëŠ”ì§€, ì°¸ì—¬ ê· í˜• ì—¬ë¶€
2. ìê¸°ì¡°ì ˆ: ëª©í‘œÂ·ê³„íšÂ·ì „ëµ ì‚¬ìš© ì—¬ë¶€, ë¶€ì¡±í•œ ë¶€ë¶„
3. ë©”íƒ€ì¸ì§€: í˜„ì¬ ë‹¨ê³„ íŒë‹¨ê³¼ í•„ìš”í•œ ì‚¬ê³  ì œì•ˆ
4. ì •ì„œì  í”¼ë“œë°±: ë°œì–¸ ì† ë¶„ìœ„ê¸° ë¶„ì„ê³¼ ì‘ì› ë©”ì‹œì§€
5. ê°œì„  ì œì•ˆ: ë°œì „ëœ ì ê³¼ êµ¬ì²´ì  ê°œì„  ë°©í–¥ 2~3ê°€ì§€
6. ì§„í–‰ ìš”ì•½: ì´ì „ íšŒì˜ì™€ ë¹„êµí•´ ë‹¬ë¼ì§„ ì  ì •ë¦¬
7. ë‹¤ìŒ íšŒì˜ ì œì•ˆ: ë‹¤ìŒ íšŒì˜ì—ì„œ ë‹¤ë£¨ë©´ ì¢‹ì„ í•µì‹¬ ëª©í‘œ ì œì‹œ

[ì‘ë‹µ í˜•ì‹ ì˜ˆì‹œ]
ì—­í•  ì •ë¦¬:
...
ìê¸°ì¡°ì ˆ:
...
ë©”íƒ€ì¸ì§€:
...
ì •ì„œì  í”¼ë“œë°±:
...
ê°œì„  ì œì•ˆ:
...
ì§„í–‰ ìš”ì•½:
...
ë‹¤ìŒ íšŒì˜ ì œì•ˆ:
...

--- ìš”ì•½ ---

ğŸ‘ ì˜í•œ ì 
...

âš ï¸ ê°œì„ í•  ì 
...

âœ¨ ë‹¤ìŒ íšŒì˜ ì œì•ˆ
...
"""


st.set_page_config(page_title="êµê³µì´", layout="centered")
st.title("ğŸ¤– êµê³µì´ ì±—ë´‡")

team_codes = {
    "AíŒ€": "2025", "BíŒ€": "2024", "CíŒ€": "2023", "DíŒ€": "2022",
    "EíŒ€": "2021", "FíŒ€": "2020"
}

folder_ids = {
    "AíŒ€": "1-9vL1B5O2LoS1uyBzPK3Y6kIfOSKG-Fo",
    "BíŒ€": "1BFqy-38ZOFEvxvqPBwRo5-SOaVSoK-oL",
    "CíŒ€": "1Ey9nh0vICcDOtQrIQg0XbLEehqNIShYb",
    "DíŒ€": "1kAb13Qipe-0xw2o6WbLXLi2xrcqjuxoc",
    "EíŒ€": "1dkSXOSTMDewbt0oGj-FZvWHPCFpTe8vK",
    "FíŒ€": "17C8Yfjvr8d3kR1XLJtjfcx80xBjaON1p"
}

for key in ["authenticated", "team_name", "meeting_text", "result_text", "selected_file"]:
    if key not in st.session_state:
        st.session_state[key] = "" if key != "authenticated" else False

# âœ… íšŒì˜ ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
def load_team_history(creds, team_name):
    sh = gspread.authorize(creds).open_by_key("1LNKXL83dNvsHDOHEkw7avxKRsYWCiIIIYKUPiF1PZGY")
    worksheet = sh.sheet1
    data = worksheet.get_all_records()
    df = pd.DataFrame(data)
    df.columns = [str(col).strip() for col in df.columns]
    if 'ì‹œê°„' not in df.columns:
        return pd.DataFrame()
    df['ì‹œê°„'] = pd.to_datetime(df['ì‹œê°„'], errors='coerce')
    return df[df['íŒ€ëª…'] == team_name].sort_values(by='ì‹œê°„')

# âœ… ë¶„ì„ ê²°ê³¼ íŒŒì‹± í•¨ìˆ˜
def extract_structured_feedback(text):
    keys = ["ì—­í•  ì •ë¦¬", "ìê¸°ì¡°ì ˆ", "ë©”íƒ€ì¸ì§€", "ì •ì„œì  í”¼ë“œë°±", "ê°œì„  ì œì•ˆ", "ì§„í–‰ ìš”ì•½", "ë‹¤ìŒ íšŒì˜ ì œì•ˆ"]
    result = {k: "" for k in keys}
    for k in keys:
        if k in text:
            try:
                after = text.split(k)[1]
                for other in keys:
                    if other != k and other in after:
                        after = after.split(other)[0]
                result[k] = after.strip()
            except:
                result[k] = ""
    return result

# âœ… ì‹œíŠ¸ ì €ì¥
def save_to_sheet(gc, team_name, title, parsed, full_text=""):
    try:
        worksheet = gc.open_by_key("1LNKXL83dNvsHDOHEkw7avxKRsYWCiIIIYKUPiF1PZGY").sheet1
        worksheet.append_row([
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            team_name,
            title,
            parsed.get("ì—­í•  ì •ë¦¬", ""),
            parsed.get("ìê¸°ì¡°ì ˆ", ""),
            parsed.get("ë©”íƒ€ì¸ì§€", ""),
            parsed.get("ì •ì„œì  í”¼ë“œë°±", ""),
            parsed.get("ê°œì„  ì œì•ˆ", ""),
            parsed.get("ì§„í–‰ ìš”ì•½", ""),
            parsed.get("ë‹¤ìŒ íšŒì˜ ì œì•ˆ", ""),
            full_text  # âœ… ì „ì²´ íšŒì˜ë¡ ì¶”ê°€
            ])
        return True
    except Exception as e:
        st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

# âœ… íšŒì˜ ìš”ì•½ ìš”ì  ì¶œë ¥
def display_summary_feedback(parsed):
    st.subheader("ğŸ“‹ íšŒì˜ ìš”ì•½ í”¼ë“œë°±")
    st.markdown(f"**ğŸ‘ ì˜í•œ ì **\n\n{parsed.get('ì—­í•  ì •ë¦¬', '')}\n{parsed.get('ìê¸°ì¡°ì ˆ', '')}")
    st.markdown(f"**âš ï¸ ê°œì„ í•  ì **\n\n{parsed.get('ê°œì„  ì œì•ˆ', '')}\n{parsed.get('ì§„í–‰ ìš”ì•½', '')}")
    st.markdown(f"**âœ¨ ë‹¤ìŒ íšŒì˜ ì œì•ˆ**\n\n{parsed.get('ë‹¤ìŒ íšŒì˜ ì œì•ˆ', '')}")

def add_dashboard(df):
    import altair as alt
    from gensim import corpora
    from gensim.models.ldamodel import LdaModel

    st.header("ğŸ“Š íŒ€ íšŒì˜ ëŒ€ì‹œë³´ë“œ")

    def clean_korean_text(text):
        import re
        text = re.sub(r"[^ê°€-í£\s]", "", text)
        words = text.split()
        stopwords = set([
            "ê·¸ë¦¬ê³ ", "ê·¸ëŸ¬ë‚˜", "ë•Œë¬¸ì—", "ë“±",
            "ìœ„í•œ", "í•˜ëŠ”", "ìˆë‹¤", "ìˆìŠµë‹ˆë‹¤", "ì´ë‹¤", "ëœë‹¤", "ê°™ë‹¤",
            "ê²½ìš°", "ì •ë„", "ë¶€ë¶„", "ë‚´ìš©", "ë°©ë²•", "í™œë™", "ê²°ê³¼", "ì œì‹œ",
            "ëŒ€í•œ", "ëŒ€í•´", "ì´ì—", "ë¡œì„œ",
            "ìœ¼ë¡œ", "ê²ƒì´", "ë¡œë¶€í„°", "ì—ê²Œ", "ëœë‹¤ë©´", "í•©ë‹ˆë‹¤", "ìˆì–´ìš”"
        ])
        return [w for w in words if len(w) > 1 and w not in stopwords and len(w) <= 6]

    df["ë¶„ì„í…ìŠ¤íŠ¸"] = df["ì „ì²´ íšŒì˜ë¡"].fillna("")

    # 1ï¸âƒ£ ì›Œë“œí´ë¼ìš°ë“œ & í‚¤ì›Œë“œ ë³€í™” ì¶”ì´
    with st.expander("ğŸ” íšŒì°¨ë³„ í•µì‹¬ í‚¤ì›Œë“œ & í‚¤ì›Œë“œ ë³€í™” ì¶”ì´", expanded=False):
        col1, col2 = st.columns([1, 1.5])

        with col1:
                if len(df) == 1:
                    selected_idx = 1
                else:
                    selected_idx = st.slider("WordCloud íšŒì°¨ ì„ íƒ", 1, len(df) - 1, 1, key="wordcloud_slider")
                text = " ".join(clean_korean_text(df.iloc[selected_idx - 1]["ë¶„ì„í…ìŠ¤íŠ¸"]))
                if not text.strip():
                    st.info("âš ï¸ í•´ë‹¹ íšŒì°¨ì—ëŠ” í‘œì‹œí•  í‚¤ì›Œë“œê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                else:
                    wordcloud = WordCloud(
                        font_path="fonts/malgun.ttf",
                        background_color='white',
                        width=600,
                        height=400,
                        max_words=50,
                        max_font_size=90,
                        prefer_horizontal=0.9,
                        colormap='Dark2'
                    ).generate(text)
                    fig1, ax1 = plt.subplots(figsize=(6, 4))
                    ax1.imshow(wordcloud, interpolation='bilinear')
                    ax1.axis("off")
                    st.pyplot(fig1)


        

        
        with col2:
            tokenized = df["ë¶„ì„í…ìŠ¤íŠ¸"].apply(clean_korean_text)
            all_words = [word for row in tokenized for word in row if len(word) <= 6]
            top_keywords = [kw for kw, _ in Counter(all_words).most_common(4)]
            trend_data = [[row.count(kw) for kw in top_keywords] for row in tokenized]
            trend_df = pd.DataFrame(trend_data, columns=top_keywords)
            trend_df["íšŒì°¨"] = [f"{i+1}íšŒì°¨" for i in range(len(df))]
            trend_df_melted = trend_df.melt(id_vars="íšŒì°¨", var_name="í‚¤ì›Œë“œ", value_name="ë¹ˆë„")

            chart = alt.Chart(trend_df_melted).mark_line(point=True).encode(
                x=alt.X("íšŒì°¨:N", title="íšŒì˜ íšŒì°¨", axis=alt.Axis(labelAngle=0)),
                y=alt.Y("ë¹ˆë„:Q", title="ë“±ì¥ ë¹ˆë„ìˆ˜", scale=alt.Scale(domain=[0, trend_df_melted["ë¹ˆë„"].max() + 1])),
                color=alt.Color("í‚¤ì›Œë“œ:N", title="ì£¼ìš” í‚¤ì›Œë“œ"),
                tooltip=["íšŒì°¨", "í‚¤ì›Œë“œ", "ë¹ˆë„"]
            ).properties(
                title="íšŒì°¨ë³„ ì£¼ìš” í‚¤ì›Œë“œ ë“±ì¥ ë¹ˆë„ ë³€í™”",
                width=500, height=300
            )
            st.altair_chart(chart, use_container_width=True)

    # 2ï¸âƒ£ LDA ë¶„ì„ & ìš”ì•½
    with st.expander("ğŸ§  ì „ì²´ íšŒì°¨ ëˆ„ì  ë°ì´í„° LDA ë¶„ì„", expanded=False):
        selected_indexes = st.multiselect("ë¶„ì„í•  íšŒì°¨ ì„ íƒ", df.index, format_func=lambda i: df.loc[i, "íšŒì˜ë¡ ì œëª©"] or f"{i+1}íšŒì°¨")

        if selected_indexes:
            selected_texts = df.loc[selected_indexes, "ë¶„ì„í…ìŠ¤íŠ¸"].apply(clean_korean_text).tolist()
            dictionary = corpora.Dictionary(selected_texts)
            corpus = [dictionary.doc2bow(text) for text in selected_texts]

            if len(dictionary) > 0 and len(corpus) > 0:
                lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=3, random_state=42)

                topic_keywords = []
                for i in range(3):
                    for word, prob in lda_model.show_topic(i, topn=5):
                        topic_keywords.append({"í† í”½": f"í† í”½ {i+1}", "í‚¤ì›Œë“œ": word, "í™•ë¥ ": prob})

                topic_df = pd.DataFrame(topic_keywords)
                chart = alt.Chart(topic_df).mark_bar().encode(
                    x=alt.X("í† í”½:N", title="í† í”½"),
                    y=alt.Y("í™•ë¥ :Q", title="ë¹„ì¤‘"),
                    color=alt.Color("í‚¤ì›Œë“œ:N"),
                    tooltip=["í† í”½", "í‚¤ì›Œë“œ", "í™•ë¥ "]
                ).properties(width=700, height=400)
                st.altair_chart(chart, use_container_width=True)

                # 3ï¸âƒ£ GPT ìš”ì•½
                try:
                    topic_summaries = []
                    for i in range(3):
                        keywords = ", ".join([word for word, _ in lda_model.show_topic(i, topn=5)])
                        topic_summaries.append(f"í† í”½ {i+1}: {keywords}")

                    summary_prompt = f"""
ë‹¤ìŒì€ íšŒì˜ ë‚´ìš©ì—ì„œ LDAë¶„ì„ì„ í†µí•´ ì¶”ì¶œëœ ì£¼ìš” í† í”½ì…ë‹ˆë‹¤.
ê° í† í”½ì€ ìì£¼ ë“±ì¥í•œ í•µì‹¬ í‚¤ì›Œë“œë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

{chr(10).join(topic_summaries)}

ì´ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ íšŒì˜ì—ì„œ ì–´ë–¤ ì£¼ì œê°€ ë…¼ì˜ë˜ì—ˆëŠ”ì§€ 3ì¤„ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
í•­ëª©ë§ˆë‹¤ ì´ëª¨ì§€ë¥¼ ë¶™ì—¬ì£¼ì„¸ìš”.
"""

                    openai_client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

                    topic_response = openai_client.chat.completions.create(
                        model="gpt-4-turbo",
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ êµìœ¡ íšŒì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì¡°ë ¥ìì…ë‹ˆë‹¤."},
                            {"role": "user", "content": summary_prompt}
                        ]
                    )
                    summary_text = topic_response.choices[0].message.content
                    st.markdown("### ğŸ§  ì´ë²ˆ íšŒì˜ì—ì„œ ë…¼ì˜ëœ ì£¼ì œ ìš”ì•½")
                    st.info(summary_text)

                except Exception as e:
                    st.warning(f"í† í”½ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")

        else:
            st.info("âš ï¸ ì„ íƒëœ íšŒì°¨ì— ëŒ€í•œ LDA ëª¨ë¸ë§ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


            
# âœ… ì¸ì¦ ë° íšŒì˜ë¡ ì„ íƒ
code_input = st.text_input("âœ… íŒ€ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
if code_input:
    team_name = next((team for team, code in team_codes.items() if code_input == code), None)
    if team_name:
        st.session_state.authenticated = True
        st.session_state.team_name = team_name
        st.success(f"ğŸ‰ ì¸ì¦ ì™„ë£Œ: {team_name}")

# âœ… ë³¸ë¬¸ ì‹¤í–‰ ë¡œì§
if st.session_state.authenticated:
    team_name = st.session_state.team_name
    folder_id = folder_ids[team_name]

    creds_info = json.loads(st.secrets["google"]["GOOGLE_SERVICE_ACCOUNT"])
    scopes = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive.readonly',
        'https://www.googleapis.com/auth/documents.readonly'
    ]
    creds = service_account.Credentials.from_service_account_info(creds_info, scopes=scopes)
    gc = gspread.authorize(creds)
    drive_service = build('drive', 'v3', credentials=creds)
    docs_service = build('docs', 'v1', credentials=creds)
    openai_client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

    team_df = load_team_history(creds, team_name)
    if not team_df.empty:
        add_dashboard(team_df)

    results = drive_service.files().list(
        q=f"'{folder_id}' in parents and mimeType='application/vnd.google-apps.document'",
        pageSize=10,
        fields="files(id, name, createdTime)"
    ).execute()
    files = results.get('files', [])

    if files:
        file_dict = {f["name"]: f["id"] for f in sorted(files, key=lambda x: x['createdTime'])}
        selected_file = st.selectbox("ğŸ“ íšŒì˜ë¡ íšŒì°¨ ì„ íƒ", list(file_dict.keys()))
        st.session_state.selected_file = selected_file

        if st.button("ğŸ” íšŒì˜ë¡ ë¶„ì„ ì‹œì‘", disabled=st.session_state.get("button_disabled", False)):
            st.session_state["show_dashboard"] = False  # âœ… ëŒ€ì‹œë³´ë“œ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.button_disabled = True
            time.sleep(2)

            try:
                doc = docs_service.documents().get(documentId=file_dict[selected_file]).execute()
                elements = doc.get("body", {}).get("content", [])
                meeting_text = ''.join(
                    elem['textRun']['content']
                    for v in elements if 'paragraph' in v
                    for elem in v['paragraph'].get('elements', []) if 'textRun' in elem
                )
                st.session_state.meeting_text = meeting_text

                context_summary = "\n".join([
                    f"[{row['ì‹œê°„']}] {row.get('íšŒì˜ë¡ ì œëª©', '')}" for _, row in team_df.iterrows()
                ])

                if team_df.shape[0] > 0:
                    last_text = str(team_df.iloc[-1].get("ê°œì„  ì œì•ˆ", "")) + str(team_df.iloc[-1].get("ì§„í–‰ ìš”ì•½", ""))
                    similarity = difflib.SequenceMatcher(None, meeting_text.strip(), last_text.strip()).ratio()
                    if similarity >= 0.9:
                        st.info("âš ï¸ ì´ì „ íšŒì˜ì™€ ë§¤ìš° ìœ ì‚¬í•©ë‹ˆë‹¤. ë™ì¼ íšŒì˜ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                with st.spinner("GPTê°€ íšŒì˜ë¡ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    response = openai_client.chat.completions.create(
                        model="gpt-4-turbo",
                        messages=[
                            {"role": "system", "content": SYSTEM_PROMPT},
                            {"role": "user", "content": f"[ê³¼ê±° íšŒì˜ ìš”ì•½]\n{context_summary}\n\n[ì´ë²ˆ íšŒì˜ ë‚´ìš©]\n{meeting_text}"}
                        ]
                    )
                    result_text = response.choices[0].message.content
                    st.session_state.result_text = result_text
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

                    parsed = extract_structured_feedback(result_text)
                    if parsed:
                        if save_to_sheet(gc, team_name, selected_file, parsed, meeting_text):
                            st.success("ğŸ“Œ êµ¬ê¸€ì‹œíŠ¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        display_summary_feedback(parsed)

            except openai.RateLimitError:
                st.warning("â±ï¸ ìš”ì²­ì´ ë„ˆë¬´ ë¹ ë¦…ë‹ˆë‹¤. 5ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            finally:
                st.session_state.button_disabled = False

        if st.session_state.result_text:
            if st.button("ğŸ“„ ë¶„ì„ ê²°ê³¼ PDFë¡œ ì €ì¥"):
                filename = f"{selected_file}_ë¶„ì„ê²°ê³¼.pdf"
                pdf = FPDF()
                pdf.add_page()
                pdf.set_font("Arial", size=12)
                for line in st.session_state.result_text.split('\n'):
                    pdf.multi_cell(0, 10, line)
                pdf.output(filename)
                with open(filename, "rb") as f:
                    st.download_button("â¬‡ï¸ PDF ë‹¤ìš´ë¡œë“œ", f, file_name=filename)
